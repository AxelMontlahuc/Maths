\documentclass[../main.tex]{subfiles}

\begin{document}
\setcounter{chapter}{29}
\chapter{Déterminant}
\tableofcontents
\clearpage

\setsection{3}
\section{Exemple}
\begin{tcolorbox}[title=Exemple 30.4, title filled=false, colframe=darkgreen, colback=darkgreen!10!white]
    On considrèe l'application : 
    \begin{align*}
        \delta:\mathbb{K}^2 \times \mathbb{K}^2\to \mathbb{K}; ((a, b), (c, d)) \mapsto ad - bc
    \end{align*}
    Montrer que cette application est bien $2$-linéaire. 
\end{tcolorbox}

\begin{align*}
    \delta \left( \begin{pmatrix}
        a \\ b
    \end{pmatrix}, \begin{pmatrix}
        c \\ d
    \end{pmatrix} + \lambda \begin{pmatrix}
        c' \\ d'
    \end{pmatrix} \right) &= \delta \left( \begin{pmatrix}
        a \\ b
    \end{pmatrix}, \begin{pmatrix}
        c + \lambda c' \\ d + \lambda d'
    \end{pmatrix} \right) \\
    &= a(d + \lambda d') - b(c + \lambda c') \\
    &= ad - bc + \lambda(ad' - bc') \\
    &= \delta \left( \begin{pmatrix}
        a \\ b
    \end{pmatrix}, \begin{pmatrix}
        c \\ d
    \end{pmatrix} \right) + \lambda \delta \left( \begin{pmatrix}
        a \\ b
    \end{pmatrix}, \begin{pmatrix}
        c' \\ d'
    \end{pmatrix} \right)
\end{align*}

\setsection{10}
\section{Détermination d'une application n-linéaire sur une base}
\begin{tcolorbox}[title=Propostion 30.11, title filled=false, colframe=lightblue, colback=lightblue!10!white]
    Soit pour tout $i\in \llbracket 1, n \rrbracket$, $(e_{i,j})_{1\leq j\leq d}$ une base de $E_i$ et pour tout $(j_1, \ldots, j_n)\in \llbracket 1, d_1 \rrbracket \times \cdots \times \llbracket 1, d_n \rrbracket$, $f_{j_1, \ldots, j_n}\in F$. \\
    Alors il existe une unique application $n$-linéaire $f:E_1\times \cdots \times E_n\to F$ telle que : 
    \begin{align*}
        \forall (j_1, \ldots, j_n)\in \llbracket 1, d_1 \rrbracket \times \cdots \times \llbracket 1, d_n \rrbracket, \varphi(e_{1,j_1}, \ldots, e_{n,j_n}) = f_{j_1, \ldots, j_n}
    \end{align*}
\end{tcolorbox}

\noindent Si $(e_{i,j})_{1\leq j\leq d}$ est une base de $E_i$ alors $((e_{1, 2}, 0, \ldots, 0, \ldots, e_{1, d}, 0, \ldots, 0), \ldots, (0, \ldots, 0, e_{n, 1}, \ldots, (0, \ldots, 0, e_{n, d})))$ est une base de $E_1\times \cdots \times E_n$. (22.16), théorème de rigidité. 

\setsection{17}
\section{Caractérisation par les transpositions}
\begin{tcolorbox}[title=Lemme 30.18, title filled=false, colframe=orange, colback=orange!10!white]
    Pour qu'une forme $f$ soit antisymétrique, il faut et il suffit que l'échange de deux variables quelconques provoque un changement de signe. 
\end{tcolorbox}

\noindent Par hypothèse, si $\tau$ est une transposition alors $\varphi(x_{\tau_1}, \ldots, x_{\tau_n}) = -\varepsilon(\tau)(x_1, \ldots, x_n)$. \\
Soit $\sigma\in S_n$. On écrit $\sigma = \tau_1\circ \cdots \circ\tau_k$ avec $\tau_i$ des transpositions. Alors : 
\begin{align*}
    \varphi(x_{\sigma_1}, \ldots, x_{\sigma_n}) &= \varphi(x_{\tau_1\circ\cdots\circ\tau_k(1)}, \ldots, x_{\tau_1\circ\cdots\circ\tau_k(n)}) \\
    &= \varepsilon(\tau_1) \varphi(x_{\tau_2\circ\cdots\circ\tau_k(1)}, \ldots, x_{\tau_2\circ\cdots\circ\tau_k(n)}) \\
    &= \varepsilon(\tau_1\circ \cdots \circ \tau_k) \varphi(x_1, \ldots, x_n) \\
    &= \varepsilon(\sigma) \varphi(x_1, \ldots, x_n)
\end{align*}

\section{Une forme alternée change de signe par transposition}
\begin{tcolorbox}[title=Lemme 30.19, title filled=false, colframe=orange, colback=orange!10!white]
    Soit $\varphi$ une forme alternée. Alors pour tout $(x_1, \ldots, x_n)\in E^n$ et tout $(i, j)\in \llbracket 1, n \rrbracket^2$ avec $i\neq j$ :
    \begin{align*}
        \varphi(x_1, \ldots, x_i, \ldots, x_j, \ldots, x_n) = -\varphi(x_1, \ldots, x_j, \ldots, x_i, \ldots, x_n)
    \end{align*}
    Cela revient à dire que pour toute transposition $\tau\in S_n$, on a :
    \begin{align*}
        \varphi(x_1, \ldots, x_n) = -\varepsilon(\tau)\varphi(x_{\tau_1}, \ldots, x_{\tau_n})
    \end{align*}
    Réciproquement, si cette condition est satisfaite et si $\mathbb{K}$ n'est pas de caractéristique $2$, alors $\varphi$ est alternée.
\end{tcolorbox}

\noindent Soit $\varphi$ alternée. \\
Soit $(x_1, \ldots, x_n)\in E^n$. \\
\begin{align*}
    0 &= \varphi(x_1, \ldots, x_i + x_j, \ldots, x_j + x_i, \ldots, x_n) \\
    &= \varphi(x_1, \ldots, x_i, \ldots, x_i, \ldots, x_n) \\
    &+ \varphi(x_1, \ldots, x_i, \ldots, x_j, \ldots, x_n) \\
    &+ \varphi(x_1, \ldots, x_j, \ldots, x_i, \ldots, x_n) \\
    &+ \varphi(x_1, \ldots, x_j, \ldots, x_i, \ldots, x_n) \\
    &= \varphi(x_1, \ldots, x_j, \ldots, x_n) + \varphi(x_1, \ldots, x_j, \ldots, x_i, \ldots, x_n) \\
\end{align*}
On suppose que $\operatorname{carac}(\mathbb{K}) \neq 2$. \\
On a :
\begin{align*}
    \varphi(x_1, \ldots, x_i, \ldots, x_i, \ldots, x_n) &= \varphi(x_1, \ldots, x_i, \ldots, x_i, \ldots, x_n) \text{ (antisymétrie)} \\
\end{align*}
Donc : 
\begin{align*}
    2\varphi(x_1, \ldots, x_i, \ldots, x_i, \ldots, x_n) &= 0
\end{align*}
Donc : 
\begin{align*}
    \varphi(x_1, \ldots, x_i, \ldots, x_i, \ldots, x_n) &= 0
\end{align*}

\setsection{20}
\section{Image d'une famille liée par une forme alternée}
\begin{tcolorbox}[title=Propostion 30.21, title filled=false, colframe=lightblue, colback=lightblue!10!white]
    Soit $(x_1, \ldots, x_n)$ une famille liée et $\varphi$ une forme alternée. Alors :
    \begin{align*}
        \varphi(x_1, \ldots, x_n) = 0
    \end{align*}
\end{tcolorbox}

\noindent Si $(x_1, \ldots, x_n)$ est liée, alors on peut écrire par exemple : 
\begin{align*}
    x_1 = \sum_{i=2}^n \lambda_i x_i
\end{align*}
Donc : 
\begin{align*}
    \varphi(x_1, \ldots, x_n) &= \varphi \left( \sum_{i=2}^{n} \lambda_i x_i, x_2, \ldots x_n \right) \\ 
    &= \sum_{i=2}^{n} \lambda_i \varphi(x_i, x_2, \ldots, x_n)
\end{align*}

\section{Forme $n$-linéaire d'un espace de dimension $n$}
\begin{tcolorbox}[title=Théorème 30.22, title filled=false, colframe=orange, colback=orange!10!white]
    Soit $E$ un espace vectoriel de dimension $n$ non nulle et $(e_1, \ldots, e_n)$ une base de $E$. 
    \begin{enumerate}
        \item Il existe une unique forme $n$-linéaire $\varphi$ sur $E$ telle que $\varphi(e_1, \ldots, e_n) = 1$.
        \item Cette forme $n$-linéaire est entièrement décrite sur les vecteurs de la base par : 
        \begin{align*}
            \begin{cases}
                \varphi(e_{i_1}, \ldots, e_{i_n}) = 0 & \text{s'il existe } j\neq k \text{ tel que } i_j = i_k \\
                \varphi(e_{\sigma(1)}, \ldots, e_{\sigma(n)}) = \varepsilon(\sigma) & \text{où } \sigma\in \mathcal{S}_n
            \end{cases}
        \end{align*}
        \item Toute autre forme $n$-linéaire alternée sur $E$ est de la forme $\lambda \varphi$, où $\lambda\in \mathbb{K}$. 
    \end{enumerate}
\end{tcolorbox}

\boxed{1, 2} \\
On utilise le théorème de rigidité des applications $n$-linéaires (30.11) en fixant l'image de chaque $(e_{i_1}, \ldots, e_{i_n})$ avec $(i_1, \ldots, i_n)\in \llbracket 1, n \rrbracket^n$. 
\begin{itemize}
    \item $\varphi(e_{i_1}, \ldots, e_{i_n}) = 0$ s'il existe $i_j - i_k$ avec $j\neq k$.
    \item $\varphi(\underbrace{e_{\sigma(1)}, \ldots, e_{\sigma(n)}}_{(i_1, \ldots, i_n) \text{ fournit alors une permutation }\sigma\in \mathcal{S}_n}) = \varepsilon(\sigma) \times \underbrace{1}_{\varphi(e_1, \ldots, e_n)}$.
\end{itemize}
Le théorème nous fournit l'existence de la forme alternée et l'unicité. \\ \\

\boxed{3} \\
Soit $\psi$ une forme $n$-linéaire alternée. On pose $\lambda = \psi(e_1, \ldots, e_n)$. 
\begin{itemize}
    \item si $\lambda = 0$, par alternance (et anitsymétrie) on a $\psi(e_{i_1}, \ldots, e_{i_n}) = 0$ pour tout $i_1, \ldots, i_n$. \\
    Par rigidité, $\psi = 0 = 0\times \varphi$. 
    \item si $\lambda\neq 0$, alors $\frac{1}{\lambda}\psi(_1, \ldots, e_n) = 1$. \\
    Par unicité (1), $\frac{1}{\lambda}\psi = \varphi$. \\
    Donc $\psi = \lambda\varphi$.
\end{itemize}

\setsection{24}
\section{Exemple}
\begin{tcolorbox}[title=Exemple 30.25, title filled=false, colframe=darkgreen, colback=darkgreen!10!white]
    On considère $E = \mathbb{R}^2$, muni de sa base canonique $e = (e_1, e_2) = ((1, 0), (0, 1))$. Soit $((a, b), (c, d))\in E^2$. Montrer que : 
    \begin{align*}
        \underset{e}{\operatorname{det}}((a, b), (c, d))= ad - bc
    \end{align*}
\end{tcolorbox}

\noindent $e = ((1, 0), (0, 1))$. \\
$((a, b), (c, d))\in (E)^2$. 
\begin{align*}
    \operatorname{det}_e((a, b), (c, d)) &= \operatorname{det}_e(ae_1 + be_2, ce_1 + de_2) \\
    &= ac\times \cancel{\operatorname{det}_e(e_1, e_1)} + ad\times \operatorname{det}_e(e_1, e_2) + bc\times \operatorname{det}_e(e_2, e_1) + bd\times \cancel{\operatorname{det}_e(e_2, e_2)} \\
    &= ad \times \operatorname{det}_e(e_1, e_2) - bc \times \operatorname{det}_e(e_1, e_2) \\
    &= (ad - bc)
\end{align*}

\section{Description du déterminant par les coordonnées}
\begin{tcolorbox}[title=Théorème 30.26, title filled=false, colframe=orange, colback=orange!10!white]
    Soit $E$ un espace vectoriel de dimension $n$ non nulle et $\mathcal{B} = (e_1, \ldots, e_n)$ une base de $E$. Soit $(x_1, \ldots, x_n)$ une famille d'éléments de $E$, dont les coordonnées sont : 
    \begin{align*}
        \forall j\in \llbracket 1, n \rrbracket, x_j = \sum_{i=1}^{n} a_{i, j} e_i \quad \text{donc} \quad \operatorname{Mat}_{\mathcal{B}}(x_j) = \begin{pmatrix}
            a_{1, j} \\
            \vdots \\
            a_{n, j}
        \end{pmatrix}
    \end{align*}
    On a alors : 
    \begin{align*}
        \underset{\mathcal{B}}{\operatorname{det}}(x_1, \ldots, x_n) = \sum_{\sigma\in \mathcal{S}_n} \varepsilon(\sigma) a_{\sigma(1), 1} \cdots a_{\sigma(n), n} = \sum_{\tau\in \mathcal{S}_n} \varepsilon(\tau) a_{1, \tau(1)} \cdots a_{n, \tau(n)}
    \end{align*}
\end{tcolorbox}

\begin{align*}
    \operatorname{det}_{\mathcal{B}}(x_1, \ldots, x_n) &= \operatorname{det}_{\mathcal{B}} \left( \sum_{i=1}^{n} a_{i_1, 1} e_{i_1}, \ldots, \sum_{i=1}^{n} a_{i_n, n} e_{i_n} \right) \\
    &= \sum_{i_1=1}^{n} \cdots \sum_{i_n=1}^{n} a_{i_1, 1} \cdots a_{i_n, n} \operatorname{det}_{\mathcal{B}}(e_{i_1}, \ldots, e_{i_n}) \text{ (multilinéarité)} \\
    &= \sum_{\{i_1, \ldots, i_n\} = \llbracket 1, n \rrbracket} a_{i_1, 1} \cdots a_{i_n, n} \operatorname{det}_{\mathcal{B}}(e_{i_1}, \ldots, e_{i_n}) \text{ (alternance)} \\
    &= \sum_{\sigma\in \mathcal{S}_n} a_{\sigma(1), 1} \cdots a_{\sigma(n), n} \underbrace{\operatorname{det}_{\mathcal{B}}(e_{\sigma(1)}, \ldots, e_{\sigma(n)})}_{= \varepsilon(\sigma)} \text{ (reformulation)} \\
    &= \sum_{\sigma\in \mathcal{S}_n} \varepsilon(\sigma) a_{1, \sigma^{-1}(1)} \cdots a_{n, \sigma^{-1}(n)} \\
    &= \sum_{\tau\in \mathcal{S}_n} \epsilon(\tau) a_{1, \tau(1)} \cdots a_{n, \tau(n)}
\end{align*}

\setsection{27}
\section{Effet d'un changement de base sur le déterminant}
\begin{tcolorbox}[title=Propostion 30.28, title filled=false, colframe=lightblue, colback=lightblue!10!white]
    Soit $\mathcal{B}$ et $\mathcal{B}'$ deux bases de $E$. Alors : 
    \begin{align*}
        \underset{\mathcal{B}}{\operatorname{det}} = \underset{\mathcal{B}}{\operatorname{det} (\mathcal{B}')} \times  \underset{\mathcal{B}'}{\operatorname{det}} 
    \end{align*}
\end{tcolorbox}

\noindent D'après le corollaire (30.27), on écrit : 
\begin{align*}
    \underset{\mathcal{B}'}{\operatorname{det}} = \lambda \underset{\mathcal{B}}{\operatorname{det}} \text{ avec } \lambda\in \mathbb{K}
\end{align*}
En particulier : 
\begin{align*}
    \operatorname{det}_{\mathcal{B}'}(\mathcal{B}) = \lambda \operatorname{det}_{\mathcal{B}}(\mathcal{B}) = \lambda
\end{align*}

\setsection{29}
\section{Caractérisation des bases par le déterminant}
\begin{tcolorbox}[title=Propostion 30.30, title filled=false, colframe=lightblue, colback=lightblue!10!white]
    Soit $E$ un espace vectoriel de dimension $n$ non nulle, muni d'une base $\mathcal{B}$. Une famille $\mathcal{F}$ de cardinal $n$ est une base si et seulement si $\operatorname{det}_\mathcal{B}(\mathcal{F})\neq 0$. 
\end{tcolorbox}

\noindent D'après (30.29), si $\mathcal{F}$ est une base alors $\operatorname{det}_\mathcal{B}(\mathcal{F})\neq 0$. \\
Si $\mathcal{F}$ n'est pas une base, alors elle est liée ($|\mathcal{F}| = n$) \\
Donc $\operatorname{det}_\mathcal{B}(\mathcal{F}) = 0$ (30.21). 

\setsection{35}
\section{Déterminant d'un produit}
\begin{tcolorbox}[title=Théorème 30.36, title filled=false, colframe=orange, colback=orange!10!white]
    Soit $A$ et $B$ dans $\mathcal{M}_n(\mathbb{K})$. Alors : 
    \begin{align*}
        \operatorname{det}(AB) = \operatorname{det}(A) \operatorname{det}(B) = \operatorname{det}(BA)
    \end{align*}
\end{tcolorbox}

\noindent Soit $A, B$ dans $\mathcal{M}_n(\mathbb{K})$. On note $A_1, \ldots, A_n$ les colonnes de $A$ et $B_1, \ldots, B_n$ les colonnes de $B$. \\
On considère l'application : 
$$\varphi: (\mathbb{K}^n)^n\to \mathbb{K};(X_1, \ldots, X_n)\mapsto \operatorname{det}_{\mathcal{B_C}}(AX_1, \ldots, AX_n)$$
$\varphi$ est une forme $n$-linéaire alternée. \\
On choisit donc $\lambda\in \mathbb{K}$ tel que $\varphi = \lambda \operatorname{det}_{\mathcal{B}_C}$
On a : 
\begin{align*}
    \varphi(\mathcal{B}_C) &= \lambda \operatorname{det}_{\mathcal{B}_C}(\mathcal{B}_C) \\
    &= \lambda \\
    &= \operatorname{det}_{\mathcal{B}_C} \left( A \begin{pmatrix}
        1 \\ 0 \\ \vdots \\ 0
    \end{pmatrix}, \ldots, A \begin{pmatrix}
        0 \\ 0 \\ \vdots \\ 1
    \end{pmatrix} \right) \\
    &= \operatorname{det}_{\mathcal{B}_C}(A_1, \ldots, A_n) \\
    &= \operatorname{det}(A)
\end{align*}
Ainsi $\varphi = \operatorname{det}(A) \operatorname{det}_{\mathcal{B}_C}$. \\
Donc : 
\begin{align*}
    \operatorname{det}(A) \operatorname{det}(B) &= \operatorname{det}(A) \operatorname{det}_{\mathcal{B}_C}(\mathcal{B}_1, \ldots, \mathcal{B}_n) \\
    &= \varphi(\mathcal{B}_1, \ldots, \mathcal{B}_n) \\
    &= \operatorname{det}_{\mathcal{B}_C}(AB_1, \ldots, AB_n) \\
    &= \operatorname{det} (AB)
\end{align*}

\setsection{39}
\section{Expression des déterminants classiques}
\begin{tcolorbox}[title=Propostion 30.40, title filled=false, colframe=lightblue, colback=lightblue!10!white]
    \begin{enumerate}
        \item On a : 
        \begin{align*}
            \begin{vmatrix}
                a & b \\
                c & d
            \end{vmatrix} = ad - bc
        \end{align*}
        \item \begin{align*}
            \begin{vmatrix}
                a & b & c \\
                d & e & f \\
                g & h & i
            \end{vmatrix} = aei + bfg + cdh - gec - hfa - idb
        \end{align*}
        Soit : diagonales descendantes moins les diagonales ascendantes. 
    \end{enumerate}
\end{tcolorbox}

\begin{enumerate}
    \setcounter{enumi}{1}
    \item $\mathcal{S}_3 = \{ \operatorname{id}, \begin{pmatrix}
        1 & 2 & 3
    \end{pmatrix}, \begin{pmatrix}
        1 & 3 & 2
    \end{pmatrix}, \begin{pmatrix}
        1 & 2
    \end{pmatrix}, \begin{pmatrix}
        1 & 3
    \end{pmatrix}, \begin{pmatrix}
        2 & 3
    \end{pmatrix} \}$
    \begin{align*}
        \operatorname{det}(A) &= \sum_{\sigma\in \mathcal{S}_3} \varepsilon(\sigma) a_{1, \sigma(1)} a_{2, \sigma(2)} a_{3, \sigma(3)} \\
        &= a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} - a_{12}a_{21}a_{33} - a_{11}a_{23}a_{32}
    \end{align*}
\end{enumerate}

\section{Invariance du déterminant par transposée}
\begin{tcolorbox}[title=Théorème 30.41, title filled=false, colframe=orange, colback=orange!10!white]
    Soit $A\in \mathcal{M}_n(\mathbb{K})$. Alors :
    \begin{align*}
        \operatorname{det}(^tA) = \operatorname{det}(A)
    \end{align*}
\end{tcolorbox}

\noindent RAF avec (30.34)

\section{Déterminant d'un endomorphisme}
\begin{tcolorbox}[title=Théorème 30.42, title filled=false, colframe=orange, colback=orange!10!white]
    Soit $f\in \mathcal{L}(E)$, où $E$ est une espace vectoriel de dimension finie non nulle. Soit $\mathcal{B}$ une base de $E$. Le scalaire $\operatorname{det}(\operatorname{Mat}_{\mathcal{B}}(f))$ ne dépnd pas de la base $\mathcal{B}$ choisie. On appelle ce scalaire \textbf{déterminant de $f$} et est noté $\operatorname{det}(f)$. 
\end{tcolorbox}

\noindent Si $\mathcal{B}$ et $\mathcal{B}'$ sont deux bases de $E$, alors $\operatorname{Mat}_{\mathcal{B}}(f)$ et $\operatorname{Mat}_{\mathcal{B}'}(f)$ sont semblables, donc elles ont le même déterminant (30.37). 

\setsection{43}
\section{Déterminant et conjugaison}
\begin{tcolorbox}[title=Propostion 30.44, title filled=false, colframe=lightblue, colback=lightblue!10!white]
    Soit $\psi:E\to F$ un isomorphisme d'espaces vectoriels de dimension finie non nulles et $u\in \mathcal{L}(E)$. Alors :
    \begin{align*}
        \operatorname{det}(\underbrace{\psi\circ u\circ \psi^{-1}}_{\in \mathcal{L}(F)}) = \operatorname{det}(u)
    \end{align*}
\end{tcolorbox}

\noindent Soit $e$ une base de $E$ et $f$ une base de $F$. 
\begin{align*}
    \operatorname{det}(\psi\circ u\circ \psi^{-1}) &= \operatorname{det}(\operatorname{Mat}_f(\psi\circ u\circ \psi^{-1})) \text{ (30.42)} \\
    &= \operatorname{det}(\operatorname{Mat}_{e,f}(\psi)\times \operatorname{Mat}_e(u)\times \operatorname{Mat}_{f,e}(\psi^{-1})) \text{ (28.42)} \\
    &= \operatorname{det}(\operatorname{Mat}_{e,f}(\psi)) \times \operatorname{det}(\operatorname{Mat}_e(u)) \times \operatorname{det}(\operatorname{Mat}_{f,e}(\psi^{-1})) \text{ (30.36)} \\
    &= \operatorname{det}(\underbrace{\operatorname{Mat}_{\psi}\times \operatorname{Mat}_{f, e}(\psi^{-1})}_{I_n}) \times \operatorname{det}(\operatorname{Mat}_e(u)) \text{ (30.36)} \\
    &= \operatorname{det}(\operatorname{Mat}_e(u)) \\
\end{align*}


\end{document}